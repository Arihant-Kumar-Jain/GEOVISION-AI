{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1455766,"sourceType":"datasetVersion","datasetId":850840},{"sourceId":4184333,"sourceType":"datasetVersion","datasetId":2466357}],"dockerImageVersionId":30236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Flood segmentation","metadata":{}},{"cell_type":"code","source":"from fastai.vision.all import *\nimport torch\n\n# Check if GPU is available and enable it\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# Set up paths\nworking_path = Path.cwd()\ninput_path = Path('/kaggle/input')\n\n# Create necessary directories\nfolders = ('train', 'valid')\nlabels = ('0', '1')\n\nfor folder in folders:\n    if not (working_path/folder).exists():\n        (working_path/folder).mkdir()\n    for label in labels:\n        if not (working_path/folder/label).exists():\n            (working_path/folder/label).mkdir()\n\n# Get image paths\ntrain_image_paths = sorted(input_path.rglob('train/*.png'))\nvalid_image_paths = sorted(input_path.rglob('test/*.png'))\nprint(f\"Found {len(train_image_paths)} training images and {len(valid_image_paths)} validation images\")\n\n# Organize images into folders based on their labels\ntry:\n    for image_path in train_image_paths:\n        label = '1' if '_1' in image_path.stem else '0'\n        with (working_path/'train'/label/image_path.name).open(mode='xb') as f:\n            f.write(image_path.read_bytes())\nexcept FileExistsError:\n    print(\"Training images have already been moved.\")\nelse:\n    print(\"Training images moved.\")\n\ntry:\n    for image_path in valid_image_paths:\n        label = '1' if '_1' in image_path.stem else '0'\n        with (working_path/'valid'/label/image_path.name).open(mode='xb') as f:\n            f.write(image_path.read_bytes())\nexcept FileExistsError:\n    print(\"Testing images have already been moved.\")\nelse:\n    print(\"Testing images moved.\")\n\n# Create DataBlock with augmentations\naugmented_dataloaders = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=GrandparentSplitter(),\n    get_y=parent_label,\n    item_tfms=RandomResizedCrop(192, min_scale=0.5),\n    batch_tfms=aug_transforms()\n).dataloaders(working_path, bs=32)\n\n# Create learner with GPU support\naugmented_learner = vision_learner(augmented_dataloaders, resnet18, metrics=error_rate)\n\n# Add model saving callback\naugmented_learner.add_cb(SaveModelCallback(monitor='error_rate', fname='best_model'))\n\n# Train model\naugmented_learner.fine_tune(9)\n\n# Save final model\naugmented_learner.save('final_model')\n\n# Function to infer on new images\ndef infer_image(image_path):\n    img = PILImage.create(image_path)\n    label, _, probabilities = augmented_learner.predict(img)\n    \n    if label == '0':\n        result = f\"Not flooded with probability {probabilities[0]*100:.2f}%\"\n    else:\n        result = f\"Flooded with probability {probabilities[1]*100:.2f}%\"\n    \n    return img, result\n\n# Test on a few images\ntest_images = sorted((input_path/'floodclassifiertestset').rglob('*.*'))\nfor i, img_path in enumerate(test_images[:5]):\n    img, result = infer_image(img_path)\n    print(f\"Image {i+1}: {result}\")\n    # Uncomment to display images if in a notebook environment\n    # display(img)\n\n# Function to load the best model for future use\ndef load_best_model():\n    learner = vision_learner(augmented_dataloaders, resnet18, metrics=error_rate)\n    learner.load('best_model')\n    return learner\n\n# Example of loading best model\n# best_model = load_best_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T09:32:42.590231Z","iopub.execute_input":"2025-03-30T09:32:42.590691Z","iopub.status.idle":"2025-03-30T09:33:22.007421Z","shell.execute_reply.started":"2025-03-30T09:32:42.590602Z","shell.execute_reply":"2025-03-30T09:33:22.006417Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nFound 270 training images and 52 validation images\nTraining images moved.\nTesting images moved.\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/44.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa39d883d79a4d42bb03d51d53083482"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>error_rate</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.917894</td>\n      <td>0.904248</td>\n      <td>0.326923</td>\n      <td>00:07</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"name":"stdout","text":"Better model found at epoch 0 with error_rate value: 0.32692307233810425.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>error_rate</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.508307</td>\n      <td>0.386174</td>\n      <td>0.211538</td>\n      <td>00:02</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.408248</td>\n      <td>0.189076</td>\n      <td>0.076923</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.357820</td>\n      <td>0.204755</td>\n      <td>0.057692</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.313139</td>\n      <td>0.247631</td>\n      <td>0.076923</td>\n      <td>00:02</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.287985</td>\n      <td>0.118160</td>\n      <td>0.038462</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.252988</td>\n      <td>0.107949</td>\n      <td>0.038462</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.215450</td>\n      <td>0.082234</td>\n      <td>0.038462</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.182943</td>\n      <td>0.069889</td>\n      <td>0.057692</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.159153</td>\n      <td>0.067807</td>\n      <td>0.038462</td>\n      <td>00:02</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"name":"stdout","text":"Better model found at epoch 0 with error_rate value: 0.21153846383094788.\nBetter model found at epoch 1 with error_rate value: 0.07692307978868484.\nBetter model found at epoch 2 with error_rate value: 0.057692307978868484.\nBetter model found at epoch 4 with error_rate value: 0.03846153989434242.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip list | grep fastai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T09:41:48.701843Z","iopub.execute_input":"2025-03-30T09:41:48.702881Z","iopub.status.idle":"2025-03-30T09:41:52.838645Z","shell.execute_reply.started":"2025-03-30T09:41:48.702843Z","shell.execute_reply":"2025-03-30T09:41:52.837495Z"}},"outputs":[{"name":"stdout","text":"fastai                                2.7.9\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}